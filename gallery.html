<html>
<head>
    
    <link href="https://fonts.googleapis.com/css?family=Dancing+Script" rel="stylesheet">

    <title>Gallery</title>
    <style>
        a:link, a:visited {
         background-color: #ec5a4c;
         color: white;
         padding: 15px 25px;
         text-align: center;
         text-decoration: none;
         display: inline-block;
         justify-content: space-around ;
       }
       
       a:hover, a:active {
         background-color:blue;
       }
     </style>
    
</head>
<body> 
    <header class="gallery" >
      
        <div class="nav"  >
                <ul> 
                    <li><a href="home.html">Home</a></li>
                    <li><a href="gallery.html">Gallery</a></li>
                    <li><a href="content.html">Contents</a></li>
                    <li><a href="advantage&conclusion.html">conclusion</a></li>
            
                </ul>
        </div>
    
        <div class="slider"></div>

        
        <section class="photos">
            
            <h2>Learnable texture transformer.</h2>
            <img src="images 1/Updated-fig-1-_-ai-for-image-996x1024.png"width=20%;/>
            <p>For texture extraction, recent approaches usually use semantic features extracted by a pre-trained classification model like VGG. However, such design has obvious drawbacks. First, the training objective of VGG network is a semantic classification label, and the high-level information is different from the low-level texture information.
               Therefore, it is not proper to use VGG features as the texture features.</p>
            
             <br>
             <br>
            
              
            <h2>Cross-scale feature integration </h2>
            <img src="images 1/Updated-fig-2_-ai-for-image-1024x369.png"width=20%;/>
            <p>A traditional transformer achieves more powerful representation by stacking, but in an image generation task, simple stacking is not effective . To solve this, the texture transformer can be further stacked in a cross-scale way with a cross-scale feature integration module. 
              The proposed texture transformers are applied in three scales: 1x, 2x, and 4x. </p>
            
              <br>
              <br>

              <img src="images 1/AI-For-Image-_1400-by-788_hero-1536x865.png"width=20%; />
              <p>The amount of visual data we accumulate around the world is mind boggling. However, not all the images are captured by high-end DSLR cameras, and very often they suffer from imperfections.
                 It is of tremendous benefit to save those degraded images so that users can reuse them for their own design or other aesthetic purposes.</p>
         
         
         
            </section>  

</body>

</html>